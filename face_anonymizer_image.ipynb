{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediapipe library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img,face_detection):\n",
    "    # Your code for face detection here\n",
    "    #convert from bgr to rgb cause it dectect with rgb range\n",
    "    img__rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    output=face_detection.process(img__rgb)  #process face_detection system\n",
    "    \n",
    "    # print(output.detections) #the score value is point to accuracy ,get boudingbox (boudingrect value with width, height) and the keypoints value is using for landmask\n",
    "    if output.detections is not None: #Cause if you detect animal face then it cannot(different object type) so you need if is not None\n",
    "\n",
    "        for detection in output.detections:\n",
    "            location_data=detection.location_data\n",
    "            bbox=location_data.relative_bounding_box\n",
    "\n",
    "            (x1,y1,w,h)=bbox.xmin,bbox.ymin,bbox.width,bbox.height \n",
    "\n",
    "            x1=int(x1*W) #get int value no float or sth else..\n",
    "            y1=int(y1*H)\n",
    "            w=int(w*W)\n",
    "            h=int(h*H)\n",
    "           \n",
    "            #we have to identify locate we wanna recognize as blur so using rectangle to detect that location\n",
    "            # cv2.rectangle(img,(x1,y1),(x1+w,y1+h),(0,255,0),10)\n",
    "\n",
    "            #blur faces\n",
    "            img[y1:y1+h,x1:x1+w,:]=cv2.blur(img[y1:y1+h,x1:x1+w,:],(30,30))\n",
    "    return img\n",
    "\n",
    "\n",
    "#read image\n",
    "img_path=r'D:\\open_cv\\opencv_fullcouse\\face_anonymizer_project\\testImg.png'\n",
    "img=cv2.imread(img_path)\n",
    "#get width,height of img\n",
    "H,W,c= img.shape\n",
    "\n",
    "#detect faces\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0,min_detection_confidence=0.5) as face_detection: #model_selection if you pass it 0 which is recognize closer when you are close to camera. Otherwise, 1 is farer\n",
    "    \n",
    "    img_processing=process_img(img,face_detection)\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    #save image            \n",
    "    cv2.imwrite(r'D:\\open_cv\\opencv_fullcouse\\face_anonymizer_project\\output.jpg',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
